{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "Nowadays transformer is a popular neural network structure in NLP. Compared to RNN, it allows more context information to flow through the net, achieving more precise result.\n",
    "and it can be trained more parallelly, requiring less time to train and perform inference. in this notebook, I'm going to clarify how a transform works.\n",
    "\n",
    "A transformer usually consists of an encoder-decoder structure. where the encoder maps the input sequence of symbol representations $(x_1, x_2, ..., x_n)$ to a sequence of continuous representations $\\mathbf{z} = (z_1, z_2, ..., z_n)$. Given $\\mathbf{z}$, the decoder generate an output sequence $(y_1, y_2, ..., y_m)$ of symbols one by one. At each step the model is auto-regressive, consuming the previously generated symbols as additional input when generating the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "\n",
    "First I will introduce some basic terminologies, you may find them boring, but it is worthy understanding them before we dive deeper.\n",
    "\n",
    "* token_ids or input_ids\n",
    "\n",
    "As with other NN models, transformer expects numeric input, but what we have is raw text during training or inference, so we need some preprocess to convert input text into some numeric representation that tranformer can understand. and the preprocess is called tokenization. what tokenization does is to chop long sentence into separate tokens, a token may be a word, or words, or part of a word, and all the unqiue tokens form a vocabulary, then map these tokens into a unique index number according to the vocabulary. and the input_ids of a sentence is the index list of the token after perform tokenization on it.\n",
    "\n",
    "* attention_mask\n",
    "\n",
    "we usually provide a batch of input texts to transformer instead of only one to improve performance, but their lengths are often different. however tranformer needs all inputs are of the same length. so the tokenizer has to do some padding or truncation to make sure the resulting input_ids are of the same length. and in padding case, we need tell transformer some tokens of the shorter sequence is padding, and should not be atttened during training or infernece, this is where attention_mask comes to help. attention_mask is a tensor of the same shape with input_ids, and for padding tokens the corresponding attention_mask are 0, otherwise 1 for non-padding tokens.\n",
    "\n",
    "* token_type_ids or segment_ids\n",
    "\n",
    "For NLP tasks like classification on pairs of sentences or QA, these require two different sequences to be joined in a single input_ids entry, which is usually performed with the help of special tokens, such as classifier ([CLS]) and separator ([SEP]) tokens. For example, BERT model builds such sequence in `[CLS] SEQUENCE_A [SEP] SEQUENCE_B [SEP]` way. and for these tasks tokenizer returns a token_type_ids entry which tells the model which sequence a token comes from.\n",
    "\n",
    "* self-attention\n",
    "\n",
    "Each element of the input finds out which other elements of the input they should attend to.\n",
    "\n",
    "\n",
    "you may refer to HuggingFace for formal definitions:\n",
    "\n",
    "* [HuggingFace transformers/glossary](https://huggingface.co/docs/transformers/glossary)\n",
    "    * [What are input IDs?](https://huggingface.co/docs/transformers/glossary#input-ids)\n",
    "    * [What are attention masks?](https://huggingface.co/docs/transformers/glossary#attention-mask)\n",
    "    * [What are token type IDs?](https://huggingface.co/docs/transformers/glossary#token-type-ids)\n",
    "\n",
    "\n",
    "## Papers\n",
    "\n",
    "- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "    - [Transformer: A Novel Neural Network Architecture for Language Understanding](https://blog.research.google/2017/08/transformer-novel-neural-network.html)\n",
    "    - [推荐: 可视化 token 间的关联](https://huggingface.co/spaces/exbert-project/exbert)\n",
    "    - [tensorflow transformer tutorial](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "    - [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)\n",
    "- BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the following section, let's display what's inside a transformer at a high level, and you may find more details from [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div class=\"mermaid-e20150f5-b829-40f1-a524-42fa163020b4\"></div>\n",
       "        <script type=\"module\">\n",
       "            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.1.0/+esm'\n",
       "            const graphDefinition = '---\\ntitle: Transformer for Machine Translation\\n---\\ngraph LR\\ninput[早上好]\\noutput[Good morning]\\ninput -- input --> transformer -- output --> output  \\n';\n",
       "            const element = document.querySelector('.mermaid-e20150f5-b829-40f1-a524-42fa163020b4');\n",
       "            const { svg } = await mermaid.render('graphDiv-e20150f5-b829-40f1-a524-42fa163020b4', graphDefinition);\n",
       "            element.innerHTML = svg;\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<mermaid.mermaid.Mermaid at 0x2d512acd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#! pip install mermaid-python\n",
    "from mermaid import Mermaid\n",
    "\n",
    "Mermaid(\"\"\"\n",
    "---\n",
    "title: Transformer for Machine Translation\n",
    "---\n",
    "graph LR\n",
    "input[早上好]\n",
    "output[Good morning]\n",
    "input -- input --> Transformer -- output --> output  \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div class=\"mermaid-4b80482a-c8d8-476c-a97a-2e31ddd74ee6\"></div>\n",
       "        <script type=\"module\">\n",
       "            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.1.0/+esm'\n",
       "            const graphDefinition = '---\\ntitle: Decode Transformer 1\\n---\\nflowchart LR\\n    input[早上好]\\n    output[Good morning] \\n    subgraph Transformer\\n        direction LR\\n        encoder --> decoder\\n    end\\n    input -- input --> encoder\\n    decoder -- output --> output\\n';\n",
       "            const element = document.querySelector('.mermaid-4b80482a-c8d8-476c-a97a-2e31ddd74ee6');\n",
       "            const { svg } = await mermaid.render('graphDiv-4b80482a-c8d8-476c-a97a-2e31ddd74ee6', graphDefinition);\n",
       "            element.innerHTML = svg;\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<mermaid.mermaid.Mermaid at 0x2d5118ee0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mermaid(\"\"\"\n",
    "---\n",
    "title: Decode Transformer 1\n",
    "---\n",
    "flowchart LR\n",
    "    input[早上好]\n",
    "    output[Good morning] \n",
    "    subgraph Transformer\n",
    "        direction LR\n",
    "        encoder --> decoder\n",
    "    end\n",
    "    input -- input --> encoder\n",
    "    decoder -- output --> output\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div class=\"mermaid-a8fc0252-371a-439f-965f-9c6ad9ad0950\"></div>\n",
       "        <script type=\"module\">\n",
       "            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.1.0/+esm'\n",
       "            const graphDefinition = '---\\ntitle: Decode Transformer 2\\n---\\n%% Encoder is a stack of encoder layers, the Decoder ditto. and the number of encoders or decoders is six in the paper,\\n%% it is not a magical number, you may adjust the number in your experiment\\nflowchart LR\\n    input[早上好]\\n    output[Good morning] \\n    subgraph Transformer\\n        direction LR\\n        subgraph Encoder\\n            direction TB\\n            e1[encoder]\\n            e2[encoder]\\n            e3[encoder]\\n            e4[encoder]\\n            e5[encoder]\\n            e6[encoder]\\n            e1 --> e2 --> e3 --> e4 --> e5 --> e6\\n        end\\n        subgraph Decoder\\n            direction BT\\n            d1[decoder]\\n            d2[decoder]\\n            d3[decoder]\\n            d4[decoder]\\n            d5[decoder]\\n            d6[decoder]\\n            d1 --> d2 --> d3 --> d4 --> d5 --> d6\\n        end\\n        Encoder --> Decoder\\n    end\\n    input -- input --> Encoder\\n    Decoder -- output --> output\\n';\n",
       "            const element = document.querySelector('.mermaid-a8fc0252-371a-439f-965f-9c6ad9ad0950');\n",
       "            const { svg } = await mermaid.render('graphDiv-a8fc0252-371a-439f-965f-9c6ad9ad0950', graphDefinition);\n",
       "            element.innerHTML = svg;\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<mermaid.mermaid.Mermaid at 0x1079c07c0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mermaid(\"\"\"\n",
    "---\n",
    "title: Decode Transformer 2\n",
    "---\n",
    "%% Encoder is a stack of encoder layers, the Decoder ditto. and the number of encoders or decoders is six in the paper,\n",
    "%% it is not a magical number, you may adjust the number in your experiment\n",
    "flowchart LR\n",
    "    input[早上好]\n",
    "    output[Good morning] \n",
    "    subgraph Transformer\n",
    "        direction LR\n",
    "        subgraph Encoder\n",
    "            direction TB\n",
    "            e1[encoder]\n",
    "            e2[encoder]\n",
    "            e3[encoder]\n",
    "            e4[encoder]\n",
    "            e5[encoder]\n",
    "            e6[encoder]\n",
    "            e1 --> e2 --> e3 --> e4 --> e5 --> e6\n",
    "        end\n",
    "        subgraph Decoder\n",
    "            direction BT\n",
    "            d1[decoder]\n",
    "            d2[decoder]\n",
    "            d3[decoder]\n",
    "            d4[decoder]\n",
    "            d5[decoder]\n",
    "            d6[decoder]\n",
    "            d1 --> d2 --> d3 --> d4 --> d5 --> d6\n",
    "        end\n",
    "        Encoder --> Decoder\n",
    "    end\n",
    "    input -- input --> Encoder\n",
    "    Decoder -- output --> output\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div class=\"mermaid-662b42b4-27a7-4335-a11a-0b124e5c31f3\"></div>\n",
       "        <script type=\"module\">\n",
       "            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.1.0/+esm'\n",
       "            const graphDefinition = '---\\ntitle: Decode Transformer 3\\n---\\n%% Encoder is a stack of encoder layers, the Decoder ditto. and the number of encoders or decoders is six in the paper,\\n%% it is not a magical number, you may adjust the number in your experiment\\ngraph LR\\n    subgraph Encoder\\n        direction BT\\n        sat1[Self-attention]\\n        ffw1[Feed Forward network]\\n        sat1 --> ffw1\\n    end\\n    subgraph Decoder\\n        direction BT\\n        sat2[Self-attention]\\n        edt[Encoder-Decoder attention]\\n        ffw2[Feed Forward network]\\n        sat2 --> edt --> ffw2\\n    end\\n    Encoder ~~~ Decoder\\n';\n",
       "            const element = document.querySelector('.mermaid-662b42b4-27a7-4335-a11a-0b124e5c31f3');\n",
       "            const { svg } = await mermaid.render('graphDiv-662b42b4-27a7-4335-a11a-0b124e5c31f3', graphDefinition);\n",
       "            element.innerHTML = svg;\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<mermaid.mermaid.Mermaid at 0x2d512ab20>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mermaid(\"\"\"\n",
    "---\n",
    "title: Decode Transformer 3\n",
    "---\n",
    "%% Encoder is a stack of encoder layers, the Decoder ditto. and the number of encoders or decoders is six in the paper,\n",
    "%% it is not a magical number, you may adjust the number in your experiment\n",
    "graph LR\n",
    "    subgraph Encoder\n",
    "        direction BT\n",
    "        sat1[Self-attention]\n",
    "        ffw1[Feed Forward network]\n",
    "        sat1 --> ffw1\n",
    "    end\n",
    "    subgraph Decoder\n",
    "        direction BT\n",
    "        sat2[Self-attention]\n",
    "        edt[Encoder-Decoder attention]\n",
    "        ffw2[Feed Forward network]\n",
    "        sat2 --> edt --> ffw2\n",
    "    end\n",
    "    Encoder ~~~ Decoder\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization result: dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "[101, 2023, 2003, 1037, 2460, 5537, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101,\n",
      " 2023,\n",
      " 2003,\n",
      " 1037,\n",
      " 2738,\n",
      " 2146,\n",
      " 5537,\n",
      " 1012,\n",
      " 2009,\n",
      " 2003,\n",
      " 2012,\n",
      " 2560,\n",
      " 2936,\n",
      " 2084,\n",
      " 1996,\n",
      " 5537,\n",
      " 1037,\n",
      " 1012,\n",
      " 102]\n",
      "[[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "input_ids: [101, 2054, 1005, 1055, 2115, 2171, 1029, 102, 2026, 2171, 2003, 9115, 1012, 102]\n",
      "decoded:  [CLS] what's your name? [SEP] my name is cherry. [SEP]\n",
      "token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "model_path = os.environ[\"HOME\"] + \"/dev-repo/model-store/bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "sequence_a = \"This is a short sequence.\"\n",
    "sequence_b = \"This is a rather long sequence. It is at least longer than the sequence A.\"\n",
    "padded_sequences = tokenizer([sequence_a, sequence_b], padding=True)\n",
    "print(\"tokenization result:\", padded_sequences.keys())\n",
    "pprint(padded_sequences[\"input_ids\"][0])\n",
    "pprint(padded_sequences[\"input_ids\"][1])\n",
    "pprint(padded_sequences[\"attention_mask\"])\n",
    "pprint(padded_sequences[\"token_type_ids\"])\n",
    "\n",
    "# what is token_type_ids?\n",
    "question = \"what's your name?\"\n",
    "answer = \"my name is cherry.\"\n",
    "encoded_dict = tokenizer(question, answer)\n",
    "print(\"input_ids:\", encoded_dict[\"input_ids\"])\n",
    "decoded = tokenizer.decode(encoded_dict[\"input_ids\"])\n",
    "print(\"decoded: \", decoded)\n",
    "#print(\"attention_mask:\", encoded_dict[\"attention_mask\"])\n",
    "print(\"token_type_ids\", encoded_dict[\"token_type_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what does self-attention do in mathematic?\n",
    "\n",
    "$$ softmax({QK^T \\over \\sqrt{d_k}}) V $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are several intermediate values when running a transformer:\n",
    "\n",
    "1. embeddings: a float vector encoding a token, and we can get it by looking up an embedding layer. its dimension is a hyperparameter we can adjust, 512 in the paper.\n",
    "2. query vectors(q): we can get it by multiplying embedding with a weight matrix called $W^Q$, its dimension is a hyperparameter we can adjust, 64 in the paper.\n",
    "3. key vectors(k): we can get it by multiplying embedding with a weight matrix called $W^K$, its dimension is a hyperparameter we can adjust, 64 in the paper.\n",
    "4. value vectors(v): we can get it by multiplying embedding with a weight matrix called $W^V$, its dimension is a hyperparameter we can adjust, 64 in the paper.\n",
    "\n",
    "with `q, k, v,` we can compute how much focus each token would be put on each position in the sequence. and you may think the conversion from embeddings to `q, k, v` is some kind of dimensionality reduction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
