# basic command options: https://pytorch.org/serve/server.html
# how to configure torchserve: https://pytorch.org/serve/configuration.html

# how to start torchserve in inference service:
# torchserve --start --ncs --ts-config=/volcvikingdb-model-store/bge_large_zh_serve.conf --log-config=/volcvikingdb-model-store/log4j2.xml --foreground

# bind inference, management API to all network interfaces with SSL enabled
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://127.0.0.1:8082

# set default_workers_per_model to 1 to prevent server from oom when debugging
default_workers_per_model=2
#default_workers_per_model=12

# Allow model specific custom python packages, Be cautious: it will slow down model loading
#install_py_dep_per_model=true

# log configuration: https://pytorch.org/serve/logging.html#modify-the-behavior-of-the-logs
# config demo: https://github.com/pytorch/serve/blob/master/frontend/server/src/main/resources/log4j2.xml 
async_logging=true
#vmargs=-Dlog4j.configurationFile=file:///volcvikingdb-model-store/log4j2.xml
#vmargs=-Dlog4j.configurationFile=file:///root/code/huggingface_store/log4j2.xml
#

model_store=/volcvikingdb-model-store/

# load all models in model-store
#load_models=all
load_models=bge_large_zh=bge_large_zh.mar

# job_queue_size: Number inference jobs that frontend will queue before backend can serve. Default: 100.
job_queue_size=50

# default_response_timeout: Timeout, in seconds, used for all models backend workers before they are deemed unresponsive and rebooted. Default: 120 seconds.
default_response_timeout=20

# unregister_model_timeout: Timeout, in seconds, used when handling an unregister model request when cleaning a process before it is deemed unresponsive and an error response is sent. Default: 120 seconds.
unregister_model_timeout=5

# disable_system_metrics : Disable collection of system metrics when set to “true”. Default value is “false”.
disable_system_metrics=true
